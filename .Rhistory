# Add unique glosses
top_20_with_glosses <- homophone_data %>%
select(lang, mb_raw, gl) %>%
rename(morph = mb_raw) %>%
distinct() %>%
left_join(top_20, by = c("lang", "morph")) %>%
distinct()
top_20_with_glosses
# Add unique glosses
top_20_with_glosses <- homophone_data %>%
select(lang, mb_raw, gl) %>%
rename(morph = mb_raw) %>%
distinct() %>%
right_join(top_20, by = c("lang", "morph", "gl"))
top_20_with_glosses
top_20
top_20_with_glosses <- homophone_data %>%
select(lang, mb_raw, gl) %>%
rename(morph = mb_raw) %>%
distinct()
View(top_20_with_glosses)
# Add unique glosses
top_20_with_glosses <- homophone_data %>%
select(lang, mb_raw, gl) %>%
rename(morph = mb_raw) %>%
distinct() %>%
summarize(gls = paste(unique(gl), collapse = ", "), .groups = "drop") %>%
left_join(top_20, by = c("lang", "morph"))
top_20_with_glosses <- homophone_data %>%
select(lang, mb_raw, gl) %>%
rename(morph = mb_raw) %>%
distinct() %>%
summarize(gls = paste(unique(gl), collapse = ", "), .groups = "drop")
top_20_with_glosses
# Add unique glosses
top_20_with_glosses <- homophone_data %>%
select(lang, mb_raw, gl) %>%
rename(morph = mb_raw) %>%
distinct()
top_20_with_glosses
# Add unique glosses
top_20_with_glosses <- homophone_data %>%
select(lang, mb_raw, gl) %>%
rename(morph = mb_raw) %>%
distinct() %>%
group_by(lang, morph) %>%
summarize(gls = paste(unique(gl), collapse = ", "), .groups = "drop") %>%
left_join(top_20, by = c("lang", "morph"))
top_20_with_glosses
top_20_with_glosses <- homophone_data %>%
select(lang, mb_raw, gl) %>%
rename(morph = mb_raw) %>%
distinct() %>%
group_by(lang, morph) %>%
summarize(gls = paste(unique(gl), collapse = ", "), .groups = "drop")
top_20_with_glosses
# Add unique glosses
top_20_with_glosses <- homophone_data %>%
select(lang, mb_raw, gl) %>%
rename(morph = mb_raw) %>%
distinct() %>%
group_by(lang, morph) %>%
summarize(gls = paste(unique(gl), collapse = ", "), .groups = "drop") %>%
right_join(top_20, by = c("lang", "morph"))
top_20_with_glosses
top_20_with_glosses <- homophone_data %>%
select(lang, mb_raw, gl) %>%
rename(morph = mb_raw) %>%
distinct() %>%
group_by(lang, morph) %>%
summarize(gls = paste(unique(gl), collapse = ", "), .groups = "drop")
top_20_with_glosses
# Add unique glosses
top_20_with_glosses <- homophone_data %>%
select(lang, mb_raw, gl) %>%
rename(morph = mb_raw) %>%
distinct() %>%
group_by(lang, morph) %>%
summarize(gls = paste(unique(gl), collapse = ", "), .groups = "drop") %>%
inner_join(top_20, by = c("lang", "morph"))
top_20_with_glosses
top_20_with_glosses <- homophone_data %>%
select(lang, mb_raw, gl) %>%
rename(morph = mb_raw) %>%
distinct() %>%
group_by(lang, morph) %>%
summarize(gls = paste(unique(gl), collapse = ", "), .groups = "drop")
top_20_with_glosses
top_20_with_glosses <- homophone_data %>%
select(lang, mb_raw, gl) %>%
rename(morph = mb_raw) %>%
distinct() %>%
group_by(lang, morph) %>%
summarize(gls = paste(unique(gl), collapse = ", "), .groups = "drop") %>%
mutate(number_of_gls = str_count(gls, ","))
top_20_with_glosses
# Add unique glosses
top_20_with_glosses <- homophone_data %>%
select(lang, mb_raw, gl) %>%
rename(morph = mb_raw) %>%
distinct() %>%
group_by(lang, morph) %>%
summarize(gls = paste(unique(gl), collapse = ", "), .groups = "drop") %>%
mutate(number_of_gls = 1+(str_count(gls, ","))) %>%
inner_join(top_20, by = c("lang", "morph"))
top_20_with_glosses
top_20
homophone_data
homophone_data
### 4) Further preprocessing related to homophones: Filtering, adding frequency and homogeneity measure
homophone_data <- doreco_data_gloss_equivalence_applied %>%
# Remove pauses
filter(!grepl("<p:>", wd)) %>%
# Word frequency
group_by(lang, wd) %>%
mutate(word_and_glosses = paste(wd, paste(unique(gl), collapse = " "), sep = " ")) %>%
group_by(lang, word_and_glosses) %>%
mutate(wd_freq = n_distinct(wd_ID)) %>%
# Remove labeled content
filter(!grepl("^<<", wd)) %>%
# Remove morphs and glosses with filler content
filter(mb != "****", gl != "****", gl != "NC", gl != "nc") %>%
# Remove rows containing NAs (may arise with monomorphemic IPU's)
filter(!is.na(speech_rate)) %>%
# Remove morph/gloss pairs with fewer than 10 occurrences
group_by(lang, mb_raw, gl) %>%
mutate(mb_freq = n_distinct(mb_ID)) %>%
filter(mb_freq >= 10) %>%
# Exclude glosses that combine various unrelated meanings
filter(!(lang == "savo1255" & (gl %in% c("DET.SG.M/DET.PL", "stand/INGR")))) %>%
filter(!(lang == "ruul1235" & (gl %in% c("1-")))) %>%
filter(!(lang == "sanz1248" & (gl %in% c("-PL")))) %>%
filter(!(lang == "nort2641" & (gl %in% c("ADP", "POP")))) %>%
# Determine homogeneity in morph types
group_by(lang, mb_raw) %>%
mutate(homogeneity_mt = if_else(n_distinct(mt) == 1, "Homogeneous", "Heterogeneous")) %>%
# Remove morphs with only one distinct gloss
mutate(n_homophones = n_distinct(gl)) %>%
filter(n_homophones > 1) %>%
# Restructure dataframe to one row = one morph
group_by(lang, mb_ID) %>%
filter(ph_ID == last(ph_ID)) %>%
ungroup()
### 5) Replace glottocodes with human-readable language names
glottocodes <- c("anal1239", "apah1238", "arap1274", "bain1259", "beja1238", "bora1263", "cabe1245", "cash1254", "dolg1241", "even1259", "goem1240", "goro1270", "hoch1243", "jeha1242", "jeju1234", "kaka1265", "kama1351", "kark1256", "komn1238", "ligh1234", "lowe1385", "movi1243", "ngal1292", "nisv1234", "nngg1234", "nort2641", "nort2875", "orko1234", "pnar1238", "port1286", "resi1247", "ruul1235", "sadu1234", "sanz1248", "savo1255", "sout2856", "sout3282", "stan1290", "sumi1235", "svan1243", "taba1259", "teop1238", "texi1237", "trin1278", "tsim1256", "urum1249", "vera1241", "warl1254", "yong1270", "yuca1254", "yura1255", "toto1304", "guri1247")
language_names <- c("Anal", "Yali", "Arapaho", "Baïnounk Gubëeher", "Beja", "Bora", "Cabécar", "Cashinahua", "Dolgan", "Evenki", "Goemai", "Gorwaa", "Hoocąk", "Jahai", "Jejuan", "Kakabe", "Kamas", "Tabaq", "Komnzo", "Light Warlpiri", "Lower Sorbian", "Movima", "Dalabon", "Nisvai", "Nǁng", "Northern Kurdish (Kurmanji)", "Northern Alta", "Fanbyak", "Pnar", "Daakie", "Resígaro", "Ruuli", "Sadu", "Sanzhi Dargwa", "Savosavo", "Nafsan (South Efate)", "English (Southern England)", "French (Swiss)", "Sümi", "Svan", "Tabasaran", "Teop", "Texistepec Popoluca", "Mojeño Trinitario", "Asimjeeg Datooga", "Urum", "Vera'a", "Warlpiri", "Yongning Na", "Yucatec Maya", "Yurakaré", "Totoli", "Gurindji")
mapping_vector <- setNames(language_names, glottocodes)
homophone_data$lang <- mapping_vector[homophone_data$lang]
# Add unique glosses
top_20_with_glosses <- homophone_data %>%
select(lang, mb_raw, gl) %>%
rename(morph = mb_raw) %>%
distinct() %>%
group_by(lang, morph) %>%
summarize(gls = paste(unique(gl), collapse = ", "), .groups = "drop") %>%
mutate(number_of_gls = 1+(str_count(gls, ","))) %>%
right_join(top_20, by = c("lang", "morph"))
top_20_with_glosses
# Add unique glosses
top_20_with_glosses <- homophone_data %>%
select(lang, mb_raw, gl) %>%
rename(morph = mb_raw) %>%
group_by(lang, morph) %>%
mutate(number_of_morphs = n()) %>%
distinct() %>%
summarize(gls = paste(unique(gl), collapse = ", "), .groups = "drop") %>%
mutate(number_of_gls = 1+(str_count(gls, ","))) %>%
right_join(top_20, by = c("lang", "morph"))
top_20_with_glosses
top_20_with_glosses <- homophone_data %>%
select(lang, mb_raw, gl) %>%
rename(morph = mb_raw) %>%
group_by(lang, morph) %>%
mutate(number_of_morphs = n())
top_20_with_glosses
top_20_with_glosses <- homophone_data %>%
select(lang, mb_raw, gl) %>%
rename(morph = mb_raw) %>%
group_by(lang, morph) %>%
mutate(number_of_morphs = n()) %>%
distinct()
top_20_with_glosses
top_20_with_glosses <- homophone_data %>%
select(lang, mb_raw, gl) %>%
rename(morph = mb_raw) %>%
group_by(lang, morph) %>%
mutate(number_of_morphs = n()) %>%
distinct() %>%
summarize(gls = paste(unique(gl), collapse = ", "), .groups = "drop")
top_20_with_glosses
# Add unique glosses
top_20_with_glosses <- homophone_data %>%
select(lang, mb_raw, gl) %>%
rename(morph = mb_raw) %>%
group_by(lang, morph) %>%
mutate(number_of_morphs = n()) %>%
distinct() %>%
group_by(lang, morph, number_of_morphs) %>%
summarize(gls = paste(unique(gl), collapse = ", "), .groups = "drop") %>%
mutate(number_of_gls = 1+(str_count(gls, ","))) %>%
right_join(top_20, by = c("lang", "morph"))
top_20_with_glosses
# Identify smallest/ largest homophone sets
hom_set_counts <- homophone_data %>%
rename(morph = mb_raw) %>%
semi_join(results_all_purity, by = c("lang", "morph")) %>%
group_by(lang, morph) %>%
reframe(count = n(), n_homophones = n_homophones) %>%
arrange(count) %>%
distinct()
smallest_hom_sets <- hom_set_counts %>%
filter(count == min(count))
largest_hom_sets <- hom_set_counts %>%
filter(count == max(count))
largest_hom_sets
smallest_hom_sets
average_hom_set <- hom_set_counts %>%
mean(count)
hom_set_counts
average_hom_set <- mean(hom_set_counts$count)
average_hom_set
# Save workspace
save.image(here("02_Models.RData"))
View(homophone_data)
### 2) Add new columns and remove columns not needed for further analysis
vowels = c("i","y","1","}","M","u","I","Y","U","e","2","@","8","7","o","E","9","3","V","O","{","6","a","&","A","Q")
voiced_consonants = c("m","F","n","J","N","b","d","g","G","B","v","D","z","Z","j","R","r","4","l","5","L","w")
voiceless_consonants = c("p","t","c","k","q",">","?","f","T","s","S","C","x","X","H","h","K","|","!","=")
# Save workspace
save.image(here("02_Models.RData"))
### 12) Flipped model (predicting morph from duration)
# Factors for the Random Forest models
factors <- c("mb_duration", "position_in_ipu", "wd_size", "speech_rate", "speaker", "wd_freq", "segmental_context_r")
predictor <- "gl"
results_all_gini_flipped <- data.frame(lang = character(), morph = character(), factor = character(), contribution = numeric(), r_sq = numeric())
# Loop to run Random Forests for each homophone set, per language
set.seed(44)
### 12) Flipped model (predicting morph from duration)
# Factors for the Random Forest models
factors <- c("mb_duration", "position_in_ipu", "wd_size", "speech_rate", "speaker", "wd_freq", "segmental_context")
results_all_gini_flipped <- data.frame(lang = character(), morph = character(), factor = character(), contribution = numeric(), r_sq = numeric())
# Loop to run Random Forests for each homophone set, per language
set.seed(44)
for(l in languages) {
morphs_raw <- unique(homophone_data$mb_raw[homophone_data$lang == l])
for(m in morphs_raw) {
print(paste(l,m)) # debugging
data_subset <- homophone_data %>% filter(lang == l, mb_raw == m) %>% select(c(all_of(factors)), all_of(predictor))
data_subset$gl <- as.factor(data_subset$gl)
if(nrow(data_subset) > 0){
if (nrow(data_subset) > 1 && length(unique(data_subset$gl)) > 1) {
rf <- randomForest(gl ~ .,
data = data_subset,
ntree = 500,
mtry = 3,
importance = TRUE)
# Gini Coefficient
contributions_gini <- rf$importance[, "MeanDecreaseGini"] / sum(rf$importance[, "MeanDecreaseGini"])
# OOB (out-of-bag) error rate
oob_error_rate <- rf$err.rate[nrow(rf$err.rate), "OOB"]
# Save results
for (f in factors) {
contribution <- contributions_gini[f]
results_all_gini_flipped <- rbind(
results_all_gini_flipped,
data.frame(lang = l,
morph = m,
factor = f,
contribution = contributions_gini[f],
oob_error = oob_error_rate)
)
}
}
}
}
}
# Rename columns for better readability
results_all_gini_flipped <- results_all_gini_flipped %>%
mutate(factor = case_when(
factor == "mb_duration"  ~ "morph_duration",
factor == "position_in_ipu" ~ "position",
factor == "wd_freq" ~ "word_frequency",
factor == "wd_size" ~ "word_size",
TRUE ~ factor
))
# Remove models that exceed 25% OOB errors
results_all_gini_flipped_unfiltered <- results_all_gini_flipped
results_all_gini_flipped <- filter(results_all_gini_flipped_unfiltered, oob_error < 0.25)
# Figure: Factor x Contribution (over all languages)
contr_factor_flipped <- ggplot(results_all_gini_flipped, aes(x = reorder(factor, contribution, FUN = mean), y = contribution)) +
stat_summary(fun = mean, geom = "point", shape = 18, color = "purple", size = 9) +
stat_summary(fun.data = mean_se, geom = "errorbar", width = 0.25, color = "purple") +
#  geom_hline(yintercept = 0.142, linetype = "dashed", color = "black") +
scale_y_continuous(labels = scales::percent) +
coord_flip(ylim = c(0, 0.4)) +
labs(x = "Factor", y = "Importance") +
theme_gray() +
theme(text = element_text(size = 32))
ggsave(filename = "img/appendix_contr_factor_flipped_37_44.png", plot = contr_factor_flipped, width = 10, height = 8, units = "in", dpi = 300)
### 13) Minimum model (removing the "speaker" variable)
# Factors for the Random Forest models
factors <- c("gl", "position_in_ipu", "wd_size", "speech_rate", "wd_freq", "segmental_context")
predictor <- "mb_duration"
results_all_purity_min <- data.frame(lang = character(), morph = character(), factor = character(), contribution = numeric(), r_sq = numeric())
# Loop to run Random Forests for each homophone set, per language
set.seed(44)
for(l in languages) {
morphs_raw <- unique(homophone_data$mb_raw[homophone_data$lang == l])
for(m in morphs_raw) {
print(paste(l,m)) # debugging
data_subset <- homophone_data %>% filter(lang == l, mb_raw == m) %>% select(c(all_of(factors)), all_of(predictor))
if(nrow(data_subset) > 0){
# Run model
rf <- randomForest(mb_duration ~ ., ntree = 500, mtry = 3, data = data_subset, importance = TRUE)
# Model statistics
r_sq = max(rf$rsq)
contributions_purity <- rf$importance[, "IncNodePurity"] / sum(rf$importance[, "IncNodePurity"])
for (f in factors) {
results_all_purity_min <- rbind(results_all_purity_min, data.frame(lang = l, morph = m, factor = f, contribution = contributions_purity[[f]], r_sq = r_sq))
}
}
}
}
# Rename columns for better readability
results_all_purity_min <- results_all_purity_min %>%
mutate(factor = case_when(
factor == "gl"  ~ "morph",
factor == "position_in_ipu" ~ "position",
factor == "wd_freq" ~ "word_frequency",
factor == "wd_size" ~ "word_size",
TRUE ~ factor
))
# Remove models below a 25% performance threshold
results_all_purity_min_unfiltered <- results_all_purity_min
results_all_purity_min <- filter(results_all_purity_min_unfiltered, r_sq > 0.25)
# Figure: Factor x Contribution (over all languages)
contr_factor_min <- ggplot(results_all_purity_min, aes(x = reorder(factor, contribution, FUN = mean), y = contribution)) +
stat_summary(fun = mean, geom = "point", shape = 18, color = "purple", size = 9) +
stat_summary(fun.data = mean_se, geom = "errorbar", width = 0.25, color = "purple") +
#  geom_hline(yintercept = 0.142, linetype = "dashed", color = "black") +
theme_minimal() +
scale_y_continuous(labels = scales::percent) +
coord_flip(ylim = c(0, 0.4)) +
labs(x = "Factor", y = "Importance") +
theme(text = element_text(size = 32))
ggsave(filename = "img/appendix_contr_factor_min_37_44.png", plot = contr_factor_min, width = 10, height = 8, units = "in", dpi = 300)
# Figure: Factor x Contribution (over all languages)
contr_factor_min <- ggplot(results_all_purity_min, aes(x = reorder(factor, contribution, FUN = mean), y = contribution)) +
stat_summary(fun = mean, geom = "point", shape = 18, color = "purple", size = 9) +
stat_summary(fun.data = mean_se, geom = "errorbar", width = 0.25, color = "purple") +
#  geom_hline(yintercept = 0.142, linetype = "dashed", color = "black") +
scale_y_continuous(labels = scales::percent) +
coord_flip(ylim = c(0, 0.4)) +
labs(x = "Factor", y = "Importance") +
theme_gray() +
theme(text = element_text(size = 32))
ggsave(filename = "img/appendix_contr_factor_min_37_44.png", plot = contr_factor_min, width = 10, height = 8, units = "in", dpi = 300)
contr_factor_min
contr_factor
### 14) Maximum model (including separate variables for left and right context, and actual segments rather than segment groups)
# Add necessary columns
factors <- c("gl", "position_in_ipu", "wd_size", "speech_rate", "wd_freq", "segmental_context_raw_r", "segmental_context_raw_l")
predictor <- "mb_duration"
results_all_purity_max <- data.frame(lang = character(), morph = character(), factor = character(), contribution = numeric(), r_sq = numeric())
# Loop to run Random Forests for each homophone set, per language
set.seed(44)
for(l in languages) {
morphs_raw <- unique(homophone_data$mb_raw[homophone_data$lang == l])
for(m in morphs_raw) {
print(paste(l,m)) # debugging
data_subset <- homophone_data %>% filter(lang == l, mb_raw == m) %>% select(c(all_of(factors)), all_of(predictor))
if(nrow(data_subset) > 0){
# Run model
rf <- randomForest(mb_duration ~ ., ntree = 500, mtry = 3, data = data_subset, importance = TRUE)
# Model statistics
r_sq = max(rf$rsq)
contributions_purity <- rf$importance[, "IncNodePurity"] / sum(rf$importance[, "IncNodePurity"])
for (f in factors) {
results_all_purity_max <- rbind(results_all_purity_max, data.frame(lang = l, morph = m, factor = f, contribution = contributions_purity[[f]], r_sq = r_sq))
}
}
}
}
# Rename columns for better readability
results_all_purity_max <- results_all_purity_max %>%
mutate(factor = case_when(
factor == "gl"  ~ "morph",
factor == "position_in_ipu" ~ "position",
factor == "wd_freq" ~ "word_frequency",
factor == "wd_size" ~ "word_size",
factor == "segmental_context_raw_l" ~ "left_context",
factor == "segmental_context_raw_r" ~ "right_context",
TRUE ~ factor
))
# Remove models below a 25% performance threshold
results_all_purity_max_unfiltered <- results_all_purity_max
results_all_purity_max <- filter(results_all_purity_max_unfiltered, r_sq > 0.25)
# Figure: Factor x Contribution (over all languages)
contr_factor_max <- ggplot(results_all_purity_max, aes(x = reorder(factor, contribution, FUN = mean), y = contribution)) +
stat_summary(fun = mean, geom = "point", shape = 18, color = "purple", size = 9) +
stat_summary(fun.data = mean_se, geom = "errorbar", width = 0.25, color = "purple") +
#  geom_hline(yintercept = 0.142, linetype = "dashed", color = "black") +
scale_y_continuous(labels = scales::percent) +
coord_flip(ylim = c(0, 0.4)) +
labs(x = "Factor", y = "Importance") +
theme_gray() +
theme(text = element_text(size = 32))
ggsave(filename = "img/appendix_contr_factor_max_37_44.png", plot = contr_factor_max, width = 10, height = 8, units = "in", dpi = 300)
contr_factor_max
homophone_data
View(homophone_data)
### 15) Model with morph_type as an additional factor
# Factors for the Random Forest models
factors <- c("gl", "position_in_ipu", "wd_size", "speech_rate", "wd_freq", "segmental_context", "mt")
predictor <- "mb_duration"
results_all_purity_mt <- data.frame(lang = character(), morph = character(), factor = character(), contribution = numeric(), r_sq = numeric())
# Loop to run Random Forests for each homophone set, per language
set.seed(44)
for(l in languages) {
morphs_raw <- unique(homophone_data$mb_raw[homophone_data$lang == l])
for(m in morphs_raw) {
print(paste(l,m)) # debugging
data_subset <- homophone_data %>% filter(lang == l, mb_raw == m) %>% select(c(all_of(factors)), all_of(predictor))
if(nrow(data_subset) > 0){
# Run model
rf <- randomForest(mb_duration ~ ., ntree = 500, mtry = 3, data = data_subset, importance = TRUE)
# Model statistics
r_sq = max(rf$rsq)
contributions_purity <- rf$importance[, "IncNodePurity"] / sum(rf$importance[, "IncNodePurity"])
for (f in factors) {
results_all_purity_mt <- rbind(results_all_purity_mt, data.frame(lang = l, morph = m, factor = f, contribution = contributions_purity[[f]], r_sq = r_sq))
}
}
}
}
# Rename columns for better readability
results_all_purity_mt <- results_all_purity_mt %>%
mutate(factor = case_when(
factor == "gl"  ~ "morph",
factor == "position_in_ipu" ~ "position",
factor == "wd_freq" ~ "word_frequency",
factor == "wd_size" ~ "word_size",
factor == "mt" ~ "morph_type",
TRUE ~ factor
))
# Remove models below a 25% performance threshold
results_all_purity_mt_unfiltered <- results_all_purity_mt
results_all_purity_mt <- filter(results_all_purity_mt_unfiltered, r_sq > 0.25)
# Figure: Factor x Contribution (over all languages)
contr_factor_mt <- ggplot(results_all_purity_mt, aes(x = reorder(factor, contribution, FUN = mean), y = contribution)) +
stat_summary(fun = mean, geom = "point", shape = 18, color = "purple", size = 9) +
stat_summary(fun.data = mean_se, geom = "errorbar", width = 0.25, color = "purple") +
#  geom_hline(yintercept = 0.142, linetype = "dashed", color = "black") +
scale_y_continuous(labels = scales::percent) +
coord_flip(ylim = c(0, 0.4)) +
labs(x = "Factor", y = "Importance") +
theme_gray() +
theme(text = element_text(size = 32))
ggsave(filename = "img/appendix_contr_factor_mt_37_44.png", plot = contr_factor_mt, width = 10, height = 8, units = "in", dpi = 300)
contr_factor_mt
contr_lang
contrmorph_language
View(n_words_per_lang)
n_words_per_lang_humanreadable <- n_words_per_lang
n_words_per_lang_humanreadable$lang <- mapping_vector[n_words_per_lang_humanreadable$lang]
n_words_per_lang_humanreadable
results_morph_purity_with_token_counts <- results_morph_purity %>%
left_join(n_words_per_lang_humanreadable, by = "lang")
results_morph_purity_with_token_counts
dataset_size_contrmorph <- ggplot(data= results_morph_purity_with_token_counts, aes(x = word_tokens, y = contribution)) +
geom_point() +
geom_smooth(method = "lm", color = "purple", linewidth = 3) +
scale_y_continuous(labels = scales::percent, limits = c(0, 0.175)) +
labs(x = "Word tokens", y = "Importance of morph") +
xlim(2,6) +
theme_gray() +
theme(text = element_text(size = 32))
dataset_size_contrmorph
dataset_size_contrmorph <- ggplot(data= results_morph_purity_with_token_counts, aes(x = word_tokens, y = contribution)) +
geom_point() +
geom_smooth(method = "lm", color = "purple", linewidth = 3) +
scale_y_continuous(labels = scales::percent, limits = c(0, 0.175)) +
labs(x = "Word tokens", y = "Importance of morph") +
#  xlim(2,6) +
theme_gray() +
theme(text = element_text(size = 32))
dataset_size_contrmorph
r_datasetsize <- cor(results_morph_purity_with_token_counts$contribution, results_morph_purity_with_token_counts$word_tokens)
model2 <- lm(contribution ~ word_tokens, data = dataset_size_contrmorph)
p_datasetsize <- summary(model2)$coefficients[2, 4]
results_morph_purity_with_token_counts
r_datasetsize <- cor(results_morph_purity_with_token_counts$contribution, results_morph_purity_with_token_counts$word_tokens)
r_datasetsize
model2 <- lm(contribution ~ word_tokens, data = results_morph_purity_with_token_counts)
p_datasetsize <- summary(model2)$coefficients[2, 4]
ggsave(filename = "img/appendix_datasetsize_contrmorph_37_44.png", plot = dataset_size_contrmorph, width = 10, height = 10, units = "in", dpi = 300)
r_datasetsize
p_datasetsize
# Save workspace
save.image(here("03_Everything.RData"))
### for internal testing:
# create a version of the homophone_data table that includes only those homophones in the final models
results_morph_purity_2 <- results_morph_purity %>%
rename(mb_raw = morph) %>%
select(lang, mb_raw)
homophone_data_only_morphs_in_model <- homophone_data %>%
inner_join(results_morph_purity_2, by=c("lang","mb_raw"))
# create a version of the results_morph_purity table that adds info and gl
homophone_data_reduced_to_important_columns <- homophone_data_only_morphs_in_model %>%
select(lang, mb_raw, mb, gl) %>%
unique()
write.csv(homophone_data_reduced_to_important_columns, "only_morphs_in_final_model.csv")
